{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Natural Language Processing.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP0HQ88PvM99Va6Vp7FzvsE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jFvqJ5yFmfpr","executionInfo":{"status":"ok","timestamp":1655351442629,"user_tz":300,"elapsed":21206,"user":{"displayName":"Blaine Moreland","userId":"14694225910648241818"}},"outputId":"af7ab8fe-509c-429a-cc25-d69afda7a1f0"},"outputs":[{"output_type":"stream","name":"stdout","text":["\r0% [Working]\r            \rHit:1 http://security.ubuntu.com/ubuntu bionic-security InRelease\n","\r0% [Connecting to archive.ubuntu.com (185.125.190.36)] [Connected to cloud.r-pr\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n","\r                                                                               \rHit:3 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n","\r0% [Waiting for headers] [Connected to cloud.r-project.org (13.227.219.25)] [Co\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Connected to cloud.r-proje\r                                                                               \rHit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Connected to cloud.r-proje\r                                                                               \rHit:5 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n","\r0% [1 InRelease gpgv 88.7 kB] [Connected to cloud.r-project.org (13.227.219.25)\r                                                                               \rHit:6 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Connected to cloud.r-proje\r                                                                               \rHit:7 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n","\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Connecting to ppa.launchpa\r                                                                               \rHit:8 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n","\r0% [1 InRelease gpgv 88.7 kB] [Connecting to ppa.launchpad.net (185.125.190.52)\r                                                                               \rHit:9 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n","Hit:10 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Ign:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Hit:12 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Reading package lists... Done\n"]}],"source":["import os\n","# Find the latest version of spark 3.0 from http://www.apache.org/dist/spark/ and enter as the spark version\n","# For example:\n","# spark_version = 'spark-3.0.3'\n","spark_version = 'spark-3.0.3'\n","os.environ['SPARK_VERSION']=spark_version\n","\n","# Install Spark and Java\n","!apt-get update\n","!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n","!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n","!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n","!pip install -q findspark\n","\n","# Set Environment Variables\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n","\n","# Start a SparkSession\n","import findspark\n","findspark.init()"]},{"cell_type":"code","source":["# Start Spark session\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.appName(\"Tokens\").getOrCreate()"],"metadata":{"id":"uZEzb492mpwS","executionInfo":{"status":"ok","timestamp":1655351452839,"user_tz":300,"elapsed":10214,"user":{"displayName":"Blaine Moreland","userId":"14694225910648241818"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from pyspark.ml.feature import Tokenizer"],"metadata":{"id":"Crlny7cQms-_","executionInfo":{"status":"ok","timestamp":1655351453100,"user_tz":300,"elapsed":264,"user":{"displayName":"Blaine Moreland","userId":"14694225910648241818"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Create sample DataFrame\n","dataframe = spark.createDataFrame([\n","  (0, \"Spark is great\"),\n","  (1, \"We are learning Spark\"),\n","  (2, \"Spark is better than hadoop no doubt\")\n","], [\"id\", \"sentence\"])\n","\n","dataframe.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IBMKC-xznXIw","executionInfo":{"status":"ok","timestamp":1655351462176,"user_tz":300,"elapsed":9078,"user":{"displayName":"Blaine Moreland","userId":"14694225910648241818"}},"outputId":"3b8118ee-8157-4bce-979f-6ac2b8dfcf15"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+--------------------+\n","| id|            sentence|\n","+---+--------------------+\n","|  0|      Spark is great|\n","|  1|We are learning S...|\n","|  2|Spark is better t...|\n","+---+--------------------+\n","\n"]}]},{"cell_type":"code","source":["# Tokenize sentences\n","tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n","tokenizer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eplTkBuAmy9J","executionInfo":{"status":"ok","timestamp":1655351466707,"user_tz":300,"elapsed":194,"user":{"displayName":"Blaine Moreland","userId":"14694225910648241818"}},"outputId":"9c85f7b4-b78f-4edd-b8a4-428b0b78cc2a"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Tokenizer_12998061812b"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["# Transform and show DataFrame\n","tokenized_df = tokenizer.transform(dataframe)\n","tokenized_df.show(truncate=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JD8sWAvtoxH0","executionInfo":{"status":"ok","timestamp":1655351544361,"user_tz":300,"elapsed":1274,"user":{"displayName":"Blaine Moreland","userId":"14694225910648241818"}},"outputId":"de972106-7c0a-43e3-fc3c-2f9d6240c8cb"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+------------------------------------+--------------------------------------------+\n","|id |sentence                            |words                                       |\n","+---+------------------------------------+--------------------------------------------+\n","|0  |Spark is great                      |[spark, is, great]                          |\n","|1  |We are learning Spark               |[we, are, learning, spark]                  |\n","|2  |Spark is better than hadoop no doubt|[spark, is, better, than, hadoop, no, doubt]|\n","+---+------------------------------------+--------------------------------------------+\n","\n"]}]},{"cell_type":"code","source":["# Create a function to return the length of a list\n","def word_list_length(word_list):\n","    return len(word_list)"],"metadata":{"id":"7h_8Gxs-nIpF","executionInfo":{"status":"ok","timestamp":1655351553390,"user_tz":300,"elapsed":204,"user":{"displayName":"Blaine Moreland","userId":"14694225910648241818"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["from pyspark.sql.functions import col, udf\n","from pyspark.sql.types import IntegerType"],"metadata":{"id":"OGnJwkyxnL5-","executionInfo":{"status":"ok","timestamp":1655351555429,"user_tz":300,"elapsed":192,"user":{"displayName":"Blaine Moreland","userId":"14694225910648241818"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Create a user defined function\n","count_tokens = udf(word_list_length, IntegerType())"],"metadata":{"id":"Q8H8VrHlnNf7","executionInfo":{"status":"ok","timestamp":1655351559970,"user_tz":300,"elapsed":206,"user":{"displayName":"Blaine Moreland","userId":"14694225910648241818"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Create our Tokenizer\n","tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n","# Transform DataFrame\n","tokenized_df = tokenizer.transform(dataframe)\n","# Select the needed columns and don't trncate results\n","tokenized_df.withColumn(\"tokens\", count_tokens(col(\"words\"))).show(truncate=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q37xE8j3pFyx","executionInfo":{"status":"ok","timestamp":1655351742562,"user_tz":300,"elapsed":1569,"user":{"displayName":"Blaine Moreland","userId":"14694225910648241818"}},"outputId":"9936899a-1c4e-4c1e-a3cc-f54843716fc8"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+------------------------------------+--------------------------------------------+------+\n","|id |sentence                            |words                                       |tokens|\n","+---+------------------------------------+--------------------------------------------+------+\n","|0  |Spark is great                      |[spark, is, great]                          |3     |\n","|1  |We are learning Spark               |[we, are, learning, spark]                  |4     |\n","|2  |Spark is better than hadoop no doubt|[spark, is, better, than, hadoop, no, doubt]|7     |\n","+---+------------------------------------+--------------------------------------------+------+\n","\n"]}]}]}